{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile01 = pd.read_json('mobile01.json', encoding='utf-8', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile01_houseapp_id = [728, 729, 730, 731, 168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把真的在講家電的板抓出來 ㄏㄏ 幸好文章裡面有topic_id可以定位他是哪個版的，不然就真的GG la\n",
    "mobile01_houseapp = mobile01[mobile01.topic_id==728]\n",
    "mobile01_houseapp = pd.concat([mobile01_houseapp, mobile01[mobile01.topic_id==729]])\n",
    "mobile01_houseapp = pd.concat([mobile01_houseapp, mobile01[mobile01.topic_id==730]])\n",
    "mobile01_houseapp = pd.concat([mobile01_houseapp, mobile01[mobile01.topic_id==731]])\n",
    "mobile01_houseapp = pd.concat([mobile01_houseapp, mobile01[mobile01.topic_id==168]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-09-04', '2020-09-08', '2020-08-17', '2020-09-08', '2020-09-09']\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "for i in mobile01_houseapp['date']:\n",
    "    temp.append(str(i)[:-9])\n",
    "print(temp[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 名稱seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#原始名稱seed\n",
    "app_name_orgin = pd.read_table('./seed/result(name).txt', sep='\\n', encoding='big5hkscs')\n",
    "name_seed_origin = []\n",
    "for i in range(len(app_name_orgin)):\n",
    "    name_seed_origin.append(app_name_orgin.title_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#策略一的seed檔\n",
    "app_name_seed_over5 = pd.read_table('./seed/name_seed_over5ws.txt', sep='\\n', encoding='utf-8')\n",
    "name_seed_over5 = []\n",
    "for i in range(len(app_name_seed_over5)):\n",
    "    name_seed_over5.append(app_name_seed_over5.title_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#策略二的seed檔\n",
    "app_name_seed_3to5 = pd.read_table('./seed/name_seed_3to5ws.txt', sep='\\n', encoding='utf-8')\n",
    "name_seed_3to5 = []\n",
    "for i in range(len(app_name_seed_3to5)):\n",
    "    name_seed_3to5.append(app_name_seed_3to5.title_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#策略二的seed檔(人工刪去不合理之seed後)\n",
    "app_name_seed_3to5_manual = pd.read_table('./seed/name_seed_3to5ws_manual.txt', sep='\\n', encoding='utf-8')\n",
    "name_seed_3to5_manual = []\n",
    "for i in range(len(app_name_seed_3to5_manual)):\n",
    "    name_seed_3to5_manual.append(app_name_seed_3to5_manual.title_name[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seed前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把有括號跟 - 的都刪掉\n",
    "def del_notation(name_seed):\n",
    "    new_name_seed = []\n",
    "    for i in name_seed:\n",
    "        pos = i.find('(')\n",
    "        temp = i[:pos] if(pos!=-1) else i\n",
    "        pos = temp.find('（')\n",
    "        temp = temp[:pos] if(pos!=-1) else temp\n",
    "        pos = temp.find('[') \n",
    "        temp = temp[:pos] if(pos!=-1) else temp\n",
    "        pos = temp.find('<')\n",
    "        temp = temp[:pos] if(pos!=-1) else temp\n",
    "        pos = temp.find('-')\n",
    "        temp = temp[:pos] if(pos!=-1) else temp\n",
    "        new_name = ''.join(temp.split())    \n",
    "        new_name_seed.append(new_name)\n",
    "        \n",
    "    return_name_seed = []\n",
    "    for i in set(new_name_seed):\n",
    "        return_name_seed.append(i)\n",
    "    return return_name_seed\n",
    "#去掉英文\n",
    "def check_only_chinese(check_str):\n",
    "    import re\n",
    "    zhPattern = re.compile(u'[\\u4e00-\\u9fa5]+')\n",
    "    for ch in check_str:\n",
    "        if zhPattern.search(ch)==None:\n",
    "            return False\n",
    "    return True\n",
    "def only_chinese_list(name_seed):\n",
    "    new_name_seed_ws_only_chinese = []\n",
    "    for i in name_seed:\n",
    "        if check_only_chinese(i):\n",
    "            new_name_seed_ws_only_chinese.append(i)\n",
    "    outputseed = []\n",
    "    for i in set(new_name_seed_ws_only_chinese):\n",
    "        outputseed.append(i)\n",
    "    return outputseed\n",
    "\n",
    "def stragety(new_name_seed, new_name_ws_list, stragety):\n",
    "    #字數>5的產品斷詞\n",
    "    #策略二:字數3~5的產品 進行斷詞組合，保留原本的+斷掉的\n",
    "    #      對於斷詞後最後一個字為獨立字的產品，再加入倒數第二個字\n",
    "    new_name_seed_ws = []\n",
    "    for i in range(len(new_name_seed)):\n",
    "        new_name = new_name_seed[i]\n",
    "        if len(new_name_seed[i])>5:\n",
    "            new_name_ws = new_name_ws_list[i]\n",
    "            new_name = new_name_ws[-1]\n",
    "            if len(new_name)==1:\n",
    "                new_name = new_name_ws[-2]+new_name_ws[-1]\n",
    "        if stragety==2:\n",
    "            if len(new_name_seed[i])>3 and len(new_name_seed[i])<=5:  #4~5個字的就斷詞後的(如果最後一個字元長度>1)+原本\n",
    "                new_name_ws = new_name_ws_list[i]\n",
    "                if len(new_name_ws[-1])>1:\n",
    "                    new_name_seed_ws.append(new_name_ws[-1])      \n",
    "        new_name_seed_ws.append(new_name)\n",
    "    outputseed = []\n",
    "    for i in set(new_name_seed_ws):\n",
    "        outputseed.append(i)\n",
    "    return outputseed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#刪除特殊符號及其裡面的文字\n",
    "del_notation_seed = del_notation(name_seed_origin)\n",
    "#只留下中文字\n",
    "only_chn_seed = only_chinese_list(del_notation_seed)\n",
    "#斷詞\n",
    "os.chdir('.//data')\n",
    "ws = WS('')\n",
    "name_ws_seed = ws(only_chn_seed,)\n",
    "os.chdir('.//..')\n",
    "#不同策略的斷詞\n",
    "name_seed_over5 = stragety(only_chn_seed, name_ws_seed, 1)\n",
    "name_seed_3to5 = stragety(only_chn_seed, name_ws_seed, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 品牌seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### brand seed 前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_notation(name_seed):\n",
    "    new_name_seed = []\n",
    "    notation_list = ['(',')', '-', '\\\\', '，', '、', '/']\n",
    "    for i in name_seed:\n",
    "        new_name = i\n",
    "        for j in notation_list:\n",
    "            new_name = new_name.replace(j, '')\n",
    "        new_name_seed.append(new_name)        \n",
    "    return_name_seed = []\n",
    "    for i in set(new_name_seed):\n",
    "        return_name_seed.append(i)\n",
    "    return return_name_seed\n",
    "\n",
    "def chn_eng_split(name_seed):\n",
    "    zhPattern = re.compile(u'[\\u4e00-\\u9fa5]+')\n",
    "    return_new_name_chn = []\n",
    "    return_new_name_eng = []\n",
    "    for i in name_seed:\n",
    "        #全部轉成小寫\n",
    "        new_name = i.lower()\n",
    "        chn_name = ''\n",
    "        eng_name = ''\n",
    "        for j in new_name: #切中英文\n",
    "            if zhPattern.search(j)==None: #is english\n",
    "                eng_name = eng_name+j\n",
    "            else:\n",
    "                chn_name = chn_name+j\n",
    "        if chn_name!='':\n",
    "            return_new_name_chn.append(chn_name)\n",
    "        if eng_name!='':\n",
    "            return_new_name_eng.append(eng_name)\n",
    "                \n",
    "    return return_new_name_chn, return_new_name_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#廠牌原始資料\n",
    "brand_seed = pd.read_table('./seed/result(brand).txt', sep='\\n', encoding='big5hkscs')\n",
    "app_brand_orgin = []\n",
    "for i in range(len(brand_seed)):\n",
    "    app_brand_orgin.append(brand_seed.title_name[i])\n",
    "    \n",
    "#廠牌處理後的資料\n",
    "brand_seed_chn_eng = []\n",
    "chn_brand, eng_brand = chn_eng_split(ignore_notation(app_brand_orgin))\n",
    "\n",
    "#去前後空格\n",
    "for i in range(len(chn_brand)):\n",
    "    chn_brand[i] = chn_brand[i].lstrip()\n",
    "    chn_brand[i] = chn_brand[i].rstrip()\n",
    "    brand_seed_chn_eng.append(chn_brand[i])\n",
    "for i in range(len(eng_brand)):\n",
    "    eng_brand[i] = eng_brand[i].lstrip()\n",
    "    eng_brand[i] = eng_brand[i].rstrip()\n",
    "    brand_seed_chn_eng.append(eng_brand[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_seed = pd.read_table('./seed/brand_seed.txt', sep='\\n', encoding='utf-8')\n",
    "brand_seed_chn_eng = []\n",
    "for i in range(len(brand_seed)):\n",
    "    brand_seed_chn_eng.append(brand_seed.title_name[i])\n",
    "brand_seed_chn_eng.remove('果汁機')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加上FindPrice網站的seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['飛利浦',\n",
       " 'cuisinart',\n",
       " 'vitamax',\n",
       " 'tanita',\n",
       " '歐姆龍',\n",
       " '賽寧',\n",
       " 'sharp',\n",
       " '雷剋蹣',\n",
       " 'frigidaire',\n",
       " '東龍',\n",
       " 'tiamo',\n",
       " 'sanyo',\n",
       " 'kozawa',\n",
       " '日本精工',\n",
       " '山水',\n",
       " '大家源',\n",
       " '三菱',\n",
       " '德國百靈',\n",
       " 'singer',\n",
       " 'toshiba',\n",
       " '勁量',\n",
       " '夏普',\n",
       " '3m',\n",
       " 'gaggia',\n",
       " '富及第',\n",
       " '鍋寶',\n",
       " '三洋',\n",
       " '泰仕',\n",
       " 'delonghi',\n",
       " '瑞軒',\n",
       " '聲寶',\n",
       " '普樂',\n",
       " 'duracell',\n",
       " 'joyoung',\n",
       " 'kolin',\n",
       " '貴夫人',\n",
       " 'bosch',\n",
       " 'heller',\n",
       " '收藏家',\n",
       " '九陽',\n",
       " 'electrolux',\n",
       " '日立',\n",
       " '瀚斯寶麗',\n",
       " 'omron',\n",
       " 'zojirushi',\n",
       " \"de'longhi\",\n",
       " '東元',\n",
       " 'teco',\n",
       " '樂金',\n",
       " 'stadler form',\n",
       " 'osim',\n",
       " 'mk seiko',\n",
       " '百靈',\n",
       " 'saeco',\n",
       " 'daikin',\n",
       " 'prosteam',\n",
       " 'toyotomi',\n",
       " 'tes',\n",
       " 'samsung',\n",
       " '大同',\n",
       " 'dainichi',\n",
       " '上豪',\n",
       " '禾聯',\n",
       " 'lg',\n",
       " 'iris',\n",
       " '白朗',\n",
       " '嘉儀',\n",
       " '北方',\n",
       " 'sharp',\n",
       " 'braun',\n",
       " '博世',\n",
       " '象印',\n",
       " 'janome',\n",
       " '車樂美',\n",
       " 'mitsubishi',\n",
       " '美泰克',\n",
       " 'westinghouse',\n",
       " 'irobot',\n",
       " 'supa fine',\n",
       " 'hannspree',\n",
       " 'sansui',\n",
       " 'vestfrost',\n",
       " '易管家',\n",
       " '西屋',\n",
       " '惠而浦',\n",
       " '晶工',\n",
       " '元山',\n",
       " 'maytag',\n",
       " 'raycop',\n",
       " '松下',\n",
       " 'coway',\n",
       " 'sampo',\n",
       " '美膳雅',\n",
       " '賀眾牌',\n",
       " '奇異',\n",
       " '萬國牌',\n",
       " '國際牌',\n",
       " '伊萊克斯',\n",
       " 'hitachi',\n",
       " '歐司朗',\n",
       " 'dyson',\n",
       " 'panasonic',\n",
       " '尚朋堂',\n",
       " 'kenmore',\n",
       " 'dirt devil',\n",
       " '金頂',\n",
       " 'xpal power',\n",
       " '勳風',\n",
       " 'ecomo',\n",
       " 'tatung',\n",
       " 'ge',\n",
       " 'whirlpool',\n",
       " '大金',\n",
       " '防潮家',\n",
       " '迪朗奇',\n",
       " 'vornado',\n",
       " 'brandt',\n",
       " '比特數位',\n",
       " 'synco',\n",
       " '小澤',\n",
       " '奇美',\n",
       " '新格',\n",
       " 'osram',\n",
       " 'vizio',\n",
       " '歌林',\n",
       " 'tiger',\n",
       " '荷蘭公主',\n",
       " 'asko',\n",
       " 'casio',\n",
       " 'philips',\n",
       " 'honeywell',\n",
       " 'miele',\n",
       " 'princess',\n",
       " '偉志牌',\n",
       " 'iqair',\n",
       " '勝家',\n",
       " 'twinbird',\n",
       " '三星',\n",
       " '虎牌',\n",
       " 'agait',\n",
       " '卡西歐',\n",
       " '東芝']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_seed = pd.read_table('./seed/findPrice_brand.txt', sep='\\n', encoding='utf-8')\n",
    "temp = []\n",
    "findprice_brand = []\n",
    "for i in range(len(brand_seed)):\n",
    "    findprice_brand.append(brand_seed.title_name[i])\n",
    "\n",
    "findprice_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_seed = pd.read_table('./seed/brand_seed_new.txt', sep='\\n', encoding='utf-8')\n",
    "temp = []\n",
    "add_findprice_brand = []\n",
    "for i in range(len(brand_seed)):\n",
    "    temp.append(brand_seed.title_name[i])\n",
    "for i in set(temp):\n",
    "    add_findprice_brand.append(i)\n",
    "add_findprice_brand.remove('果汁機')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每個回文的長度\n",
    "first_sentence_len = []\n",
    "reply_sentence_len = []\n",
    "for idx in range(len(mobile01_houseapp.content_list)): #對於每一個討論串\n",
    "    for j in range(len( mobile01_houseapp.content_list.iloc[idx])): #對於指定討論串中的每樓\n",
    "        if j==0:\n",
    "            first_sentence_len.append(len(mobile01_houseapp.content_list.iloc[idx][j]['content']))\n",
    "        else:\n",
    "            reply_sentence_len.append(len(mobile01_houseapp.content_list.iloc[idx][j]['content']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seed match statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed長度： 557\n",
      "在每篇文章有提到seed中產品的比例是:3003/3848\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "# brand_seed_chn_eng\n",
    "# add_findprice_brand\n",
    "cant_list_brand = []\n",
    "name_seed = name_seed_3to5_manual\n",
    "for idx in range(len(mobile01_houseapp.content_list)): #對於每一個討論串\n",
    "    flag = False\n",
    "    for i in name_seed: #對於每個產品名稱\n",
    "        if i in mobile01_houseapp.title.iloc[idx].lower(): #對於文章標題\n",
    "            flag = True\n",
    "#         elif i in mobile01_houseapp.content_list.iloc[idx][0]['content']: #樓主有提到\n",
    "#             flag = True\n",
    "        for j in range(len( mobile01_houseapp.content_list.iloc[idx])): #對於指定討論串中的每樓\n",
    "            if i in mobile01_houseapp.content_list.iloc[idx][j]['content'].lower():\n",
    "                flag = True\n",
    "        if flag:\n",
    "            break\n",
    "\n",
    "    if flag:\n",
    "        count = count+1\n",
    "#     else:\n",
    "#         cant_list_brand.append(idx)\n",
    "#     if(idx%100==0):\n",
    "#         print(idx)\n",
    "print('seed長度：', len(name_seed))\n",
    "print('在每篇文章有提到seed中產品的比例是:{yes}/{total}'.format(yes=count, total=len(mobile01_houseapp.content_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "奇美\n",
      "元山家電\n"
     ]
    }
   ],
   "source": [
    "for i in add_findprice_brand:\n",
    "    if i in name_seed_3to5:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有提到seed的句子中，是否包含其他seed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "count_list = []\n",
    "count_list_sentence = []\n",
    "count_list_name = []\n",
    "all_count = 0\n",
    "name_seed = add_findprice_brand\n",
    "for idx in range(len(mobile01_houseapp.content_list)): #對於每一個討論串\n",
    "    #看文章標題中有幾個指定種子\n",
    "    count = 0\n",
    "    all_count = all_count+1\n",
    "    name_list = []\n",
    "    for i in name_seed: #對於每個產品名稱\n",
    "        #文章標題跟樓主合併成同一個文\n",
    "        sentence = mobile01_houseapp.title.iloc[idx].lower()+mobile01_houseapp.content_list.iloc[idx][0]['content'].lower()\n",
    "        if i in sentence: \n",
    "            flag = True\n",
    "            for x in name_list: #看已經找到的種子間有沒有包含關係\n",
    "                if i in x or x in i:\n",
    "                    flag = False\n",
    "            if flag:\n",
    "                count = count+1\n",
    "                name_list.append(i)\n",
    "    if count>0:\n",
    "        count_list.append(count)\n",
    "#        count_list_sentence.append(mobile01_houseapp.title.iloc[idx].lower())\n",
    "        count_list_sentence.append(sentence)\n",
    "        count_list_name.append(name_list)\n",
    "    #看樓討論串中有幾個指定種子    \n",
    "    for j in range(1,len( mobile01_houseapp.content_list.iloc[idx])): #對於指定討論串中的每樓\n",
    "        all_count = all_count+1\n",
    "        count = 0\n",
    "        name_list = []\n",
    "        for i in name_seed:\n",
    "            if i in mobile01_houseapp.content_list.iloc[idx][j]['content'].lower():\n",
    "                flag = True\n",
    "                for x in name_list: #看已經找到的種子間有沒有包含關係\n",
    "                    if i in x or x in i:\n",
    "                        flag = False\n",
    "                if flag:\n",
    "                    name_list.append(i)\n",
    "                    count = count+1\n",
    "        if count>0:\n",
    "            count_list.append(count)\n",
    "            count_list_sentence.append(mobile01_houseapp.content_list.iloc[idx][j]['content'].lower())\n",
    "            count_list_name.append(name_list)\n",
    "\n",
    "    if(idx%1000==0):\n",
    "        print(idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 耍腦NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_brand_seed = pd.read_table('./爬蟲/result(brand).txt', sep='\\n', encoding='big5hkscs')\n",
    "brand_seed = []\n",
    "for i in range(len(app_brand_seed)):\n",
    "    brand_seed.append(app_brand_seed['台芝'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = []\n",
    "seeds.append(name_seed)\n",
    "seeds.append(brand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER_label(sentence, seeds, entity):\n",
    "    label = []\n",
    "    for j in range(len(sentence)):\n",
    "        label.append('O')\n",
    "    for e in entity:\n",
    "        if e == 'APP':\n",
    "            seed = seeds[0]\n",
    "        elif e == 'BRAND':\n",
    "            seed = seeds[1]\n",
    "        elif e == 'TYPE':\n",
    "            seed = seeds[2]\n",
    "        else:\n",
    "            seed = seeds[0]\n",
    "        for i in seed: #對於每個產品名稱\n",
    "            if i in sentence: #如果產品有出現在句子中\n",
    "                index = [m.start() for m in re.finditer(i, sentence)]\n",
    "                for ind in index: #對於每個有出現在句子中的產品                    \n",
    "                    for idx_label in range(len(i)):\n",
    "                        if idx_label == 0:\n",
    "                            label[idx_label+ind] = 'B-'+e\n",
    "                        elif idx_label == len(i)-1:\n",
    "                            label[idx_label+ind] = 'E-'+e\n",
    "                        else :\n",
    "                            label[idx_label+ind] = 'I-'+e\n",
    "                for ind in range(len(sentence)):#種子中可能會有實體是有包含關係的，如電風扇、風扇\n",
    "                    if(ind>0):\n",
    "                        if(label[ind-1]=='B-'+e and label[ind]=='B-'+e):\n",
    "                            label[ind] = 'I-'+e\n",
    "                    elif(ind<len(sentence)-1):\n",
    "                        if(label[ind+1]=='E-'+e and label[ind]=='E-'+e):\n",
    "                            label[ind] = 'I-'+e\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 從後面斷出的段落再做entity比對"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出有提到entity的文\n",
    "write_sentence = []\n",
    "write_label = []\n",
    "for idx in range(len(mobile01_houseapp)): #每個討論串\n",
    "#     sentence = mobile01_houseapp.content_list.iloc[idx][0]['content'].replace(\" \", \"\")#某討論串的首一樓\n",
    "#     sentence = sentence.replace('\\t', '')\n",
    "#     sentence = sentence.replace('\\n', '')\n",
    "#     sentence = sentence.replace('\\xa0', '')\n",
    "    sentence = mobile01_houseapp.content_list.iloc[idx][0]['content']\n",
    "#    sentence = \"\".join(sentence.split())\n",
    "    flag = False\n",
    "    for name in name_seed:\n",
    "        if(name in sentence):\n",
    "            flag = True\n",
    "            break\n",
    "    if(flag): #該句子裡面有完全匹配的家電種子\n",
    "        #先切句子\n",
    "        if(len(sentence)>300):\n",
    "            index = [] #所有name實體在句子中的位置\n",
    "            for name in name_seed: \n",
    "                if(name in sentence):\n",
    "                    for m in re.finditer(name, sentence):\n",
    "                        index.append(m.start())\n",
    "            index = collect_cut_sentence(index)\n",
    "            for cut_idx in index:\n",
    "                new_sen, _, _ = cut_sentence(sentence, cut_idx, 10,200, 50, sentence_end_list)\n",
    "                new_sen = ''.join(new_sen.split()) #去掉空白跟分隔符號\n",
    "                write_sentence.append(new_sen)\n",
    "                write_label.append(NER_label(new_sen, seeds, ['APP', 'BRAND']))\n",
    "        else:\n",
    "                sentence = ''.join(sentence.split())\n",
    "                write_sentence.append(sentence)\n",
    "                write_label.append(NER_label(sentence, seeds, ['APP', 'BRAND']))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/77262\n",
      "10000/77262\n",
      "15000/77262\n",
      "20000/77262\n",
      "25000/77262\n",
      "30000/77262\n",
      "35000/77262\n",
      "40000/77262\n",
      "45000/77262\n",
      "50000/77262\n",
      "55000/77262\n",
      "60000/77262\n",
      "65000/77262\n",
      "70000/77262\n",
      "75000/77262\n",
      "write 73220 sentences\n",
      "average sentence length: 63.41343895110626\n",
      "max sentence length: 300\n",
      "min sentence length: 3\n"
     ]
    }
   ],
   "source": [
    "#自己切斷落\n",
    "##看各種種子在句子裡的出現情況\n",
    "##廠牌: add_findprice_brand\n",
    "##產品: name_seed_3to5_manual\n",
    "##seq_txt: 用句尾符號切的句子\n",
    "brand_seed = add_findprice_brand\n",
    "name_seed = name_seed_3to5_manual\n",
    "\n",
    "name_label_list = []\n",
    "brand_label_list = []\n",
    "label_sentence_list = []\n",
    "sentence_list = []\n",
    "sentence_len_list = []\n",
    "\n",
    "count = 0\n",
    "last_sent = 'jsidfj'\n",
    "for sentence in seq_txt: #for all sentence\n",
    "    sentence = str(sentence)\n",
    "    if last_sent not in sentence:\n",
    "        sentence = sentence.lstrip('=') #去掉前面的等於\n",
    "        name_label = 0\n",
    "        brand_label = 0\n",
    "        if sentence.find('wrote:')>0:\n",
    "            sentence = sentence[sentence.find('wrote:')+6:]\n",
    "        if sentence.find('(恕刪)')>0:\n",
    "            sentence = sentence[sentence.find('(恕刪)')+4:]\n",
    "        #delete url\n",
    "        context = re.sub(\"http://[a-zA-z./\\d]*\",\"\",context)\n",
    "        sentence = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', sentence, flags=re.MULTILINE)            \n",
    "        label_sentence = str(sentence)\n",
    "        if len(sentence)>2:\n",
    "            for name in name_seed:\n",
    "                all_find = [m.start() for m in re.finditer(name, label_sentence)]\n",
    "                if len(all_find)>0:\n",
    "                    name_label = name_label+1\n",
    "                    for i in all_find: #label\n",
    "                        str_list = list(label_sentence)\n",
    "                        str_list.insert(i+len(name), '</PD>')\n",
    "                        str_list.insert(i, '<PD>')\n",
    "                        label_sentence = ''.join(str_list)\n",
    "            for brand in brand_seed:\n",
    "                all_find = [m.start() for m in re.finditer(brand, label_sentence)]\n",
    "                if len(all_find)>0:\n",
    "                    brand_label = brand_label+1\n",
    "                    for i in all_find: #label\n",
    "                        str_list = list(label_sentence)\n",
    "                        str_list.insert(i+len(brand), '</BR>')\n",
    "                        str_list.insert(i, '<BR>')\n",
    "                        label_sentence = ''.join(str_list)\n",
    "\n",
    "            name_label_list.append(name_label)\n",
    "            brand_label_list.append(brand_label)\n",
    "            label_sentence_list.append(label_sentence)\n",
    "            sentence_len_list.append(len(sentence))\n",
    "            sentence_list.append(sentence)\n",
    "    last_sent = sentence        \n",
    "    count = count+1\n",
    "    if count%5000 == 0:\n",
    "        print('{}/{}'.format(count,len(seq_txt)))\n",
    "            \n",
    "print('write {} sentences'.format(len(sentence_list)))\n",
    "print('average sentence length:', np.mean(sentence_len_list))\n",
    "print('max sentence length:', max(sentence_len_list))\n",
    "print('min sentence length:', min(sentence_len_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_label_list_4to200\n",
    "brand_label_list_4to200 \n",
    "label_sentence_list_4to200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特殊符號前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textClean(context):\n",
    "    # * Remove links:\n",
    "    # context = re.sub(\"http://[a-zA-z./\\d]*\",\"\",context)\n",
    "    # * Remove emoji: \"並不完全\"\n",
    "    try:  \n",
    "        emoji = re.compile(u'[\\U00010000-\\U0010ffff]')  \n",
    "    except re.error:  \n",
    "        emoji = re.compile(u'[\\uD800-\\uDBFF][\\uDC00-\\uDFFF]')  \n",
    "    context = emoji.sub(\"\",context)\n",
    "\n",
    "    # * Extract and remove tags:\n",
    "    # tags = re.findall(\"#(.{0,30})#\",context)\n",
    "    # context = re.sub(\"#.{0,30}#\",\"\",context)\n",
    "\n",
    "    # * Extract and remove @somebody:\n",
    "    # at = re.findall(\"@([^@]{0,30})\\s\",context)\n",
    "    # context = re.sub(\"@([^@]{0,30})\\s\",\"\",context)\n",
    "    # at+= re.findall(\"@([^@]{0,30})）\",context)\n",
    "    # context = re.sub(\"@([^@]{0,30})）\",\"\",context)\n",
    "\n",
    "    # * Extract and remove english letters:\n",
    "    # english = re.findall(\"[a-z]+\",context)\n",
    "    # context = re.sub(\"[a-z]+\",\"\",context)\n",
    "\n",
    "    # * Remove punctuation:\n",
    "    context = re.sub(\"[￣█▄██▍◥◣◢◤▌▲▼❤♥▂▉＠～☆＊：.｡.o≧▽≦—﹍＊╮╯▽╰╭★.＿oφ－$%^*☞◆]\", \"\", context)\n",
    "\n",
    "    # context = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",context)\n",
    "    # context = re.sub(\"[【】╮╯▽╰╭★→「」]+\",\"\",context)\n",
    "    # context = re.sub(\"！，❤。～《》：（）【】「」？”“；：、\".decode(\"utf8\"),\"\",context)\n",
    "\n",
    "    # * Remove space:\n",
    "    # context = re.sub(\"\\s\",\"\",context)\n",
    "\n",
    "\n",
    "    # * Remove ....:\n",
    "    context = re.sub(\"\\.*\",\"\",context)\n",
    "\n",
    "    return  context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 寫出資料(寫完整資料)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_id_list = []\n",
    "topic_list = [] #\n",
    "sentence_list = [] #句子\n",
    "sentence_len_list = [] #句子長度\n",
    "reply_seq = [] #幾樓\n",
    "for idx in range(len(mobile01_houseapp)): #每篇文\n",
    "    data = mobile01_houseapp.iloc[idx]\n",
    "    count = 0\n",
    "    topic_id = mobile01_houseapp.iloc[idx]['thread_id']\n",
    "    topic = mobile01_houseapp.iloc[idx]['title']\n",
    "    for reply in range(len(data['content_list'])): #每篇文的每個回文\n",
    "        topic_id_list.append(topic_id)\n",
    "        topic_list.append(topic)\n",
    "        reply_seq.append(count)\n",
    "        sentence = data['content_list'][count]['content']\n",
    "        sentence_list.append(sentence)\n",
    "        sentence_len_list.append(len(sentence))\n",
    "        count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共寫了2226個回文(含樓主)\n",
      "共寫了9881個貼文串\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "count = 0\n",
    "count_build = 0\n",
    "sentence_threshold = 1000\n",
    "with open('test_label_1000.csv', 'a', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['文章id', '文章標題', '文章內容', '文章長度', '樓層'])\n",
    "    cantwrite=0\n",
    "    for i in range(len(topic_id_list)):\n",
    "        if reply_seq[i]==0:\n",
    "            if sentence_len_list[i]>sentence_threshold:#樓主的文字threshold字就不要寫這串貼文\n",
    "                cantwrite=topic_id_list[i]\n",
    "            else:\n",
    "                count_build = count_build+1\n",
    "                \n",
    "        if topic_id_list[i]!=cantwrite:\n",
    "            if reply_seq[i]==0:\n",
    "                count = count+1\n",
    "                writer.writerow([topic_id_list[i], topic_list[i], topic_list[i]+'\\n'+sentence_list[i], sentence_len_list[i], reply_seq[i]])                \n",
    "            elif reply_seq[i]<=5:\n",
    "                count = count+1\n",
    "                writer.writerow([topic_id_list[i], topic_list[i], sentence_list[i], sentence_len_list[i], reply_seq[i]])\n",
    "print('共寫了{}個回文(含樓主)'.format(count_build))\n",
    "print('共寫了{}個貼文串'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "number: 3099\n"
     ]
    }
   ],
   "source": [
    "#加上回文串後的限制\n",
    "sentence_threshold = 1000\n",
    "with open('test_label_'+str(sentence_threshold)+'_all.csv', 'a', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['文章id', '文章標題', '文章內容', '文章長度', '最高樓層'])\n",
    "    topic_list = []\n",
    "    sent_list = []\n",
    "    sent_count_list = []\n",
    "    max_seq_list = []\n",
    "    for idx in range(len(mobile01_houseapp)): #每篇文\n",
    "        data = mobile01_houseapp.iloc[idx]\n",
    "        topic_id = mobile01_houseapp.iloc[idx]['thread_id']\n",
    "        topic = mobile01_houseapp.iloc[idx]['title']\n",
    "        sentence = '【標題】\\n'+mobile01_houseapp.iloc[idx]['title']\n",
    "        sent_count = len(sentence)\n",
    "        #30<樓主文+標題<1000才寫\n",
    "        if len(data['content_list'][0]['content']+topic)<sentence_threshold and len(data['content_list'][0]['content']+topic)>30: \n",
    "            max_seq = 0\n",
    "            for i in range(len(data['content_list'])):\n",
    "                if sent_count+len(data['content_list'][i]['content'])>sentence_threshold:\n",
    "                    break\n",
    "                else:\n",
    "                    if i == 0:\n",
    "                        sentence = sentence+'\\n【樓主】\\n'+data['content_list'][i]['content']\n",
    "                    else:\n",
    "                        sentence = sentence+'\\n【'+str(i)+'樓】\\n'+data['content_list'][i]['content']                        \n",
    "                    sent_count = sent_count+len(data['content_list'][i]['content'])\n",
    "                max_seq = i\n",
    "            topic_list.append(topic)\n",
    "            sent_list.append(sentence)\n",
    "            sent_count_list.append(sent_count)\n",
    "            max_seq_list.append(max_seq)\n",
    "            writer.writerow([topic_id, topic, sentence, sent_count, max_seq])\n",
    "print('done')\n",
    "print('number:', len(topic_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共寫了54121個文\n"
     ]
    }
   ],
   "source": [
    "#write text\n",
    "count = 0\n",
    "with open('test_label_all.txt', 'a', encoding='utf-8') as file:\n",
    "    for idx in range(len(mobile01_houseapp)): #每篇文\n",
    "        data = mobile01_houseapp.iloc[idx]\n",
    "        file.write(data['title']+'\\n') #write title\n",
    "        count=count+1\n",
    "        for i in range(len(data['content_list'])):\n",
    "            file.write(data['content_list'][i]['content'].replace('\\n','。')+'\\n')\n",
    "            count=count+1\n",
    "print('共寫了{}個文'.format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自己切斷落"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共寫了77262個文\n"
     ]
    }
   ],
   "source": [
    "#單純用句號驚嘆號問號切句子長度\n",
    "import re\n",
    "count = 0\n",
    "max_len = 300\n",
    "min_len = 30\n",
    "seq_len = []\n",
    "seq_txt = []\n",
    "with open('test_label_endnotation.txt', 'a', encoding='utf-8') as file:\n",
    "    for idx in range(len(mobile01_houseapp)): #每篇文\n",
    "        data = mobile01_houseapp.iloc[idx]\n",
    "        sentence = ''.join(data['title'].split())\n",
    "        seq_txt.append(sentence)\n",
    "        seq_len.append(len(sentence))\n",
    "        file.write(sentence+'\\n') #write title 去掉空白符號\n",
    "        count=count+1\n",
    "        for i in range(len(data['content_list'])):\n",
    "            sentence = ''.join(data['content_list'][i]['content'].split())\n",
    "    #        end_notation = ['。','?', '!', '？', '！']\n",
    "            sentence = re.split('。|!|？|！|\\?', str(sentence))\n",
    "            for subsentence in sentence:\n",
    "                if len(subsentence)>=min_len and len(subsentence)<=max_len:\n",
    "                    seq_txt.append(subsentence)\n",
    "                    seq_len.append(len(subsentence))\n",
    "                    file.write(subsentence+'\\n')\n",
    "                    count=count+1\n",
    "print('共寫了{}個文'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子數量: 120864\n",
      "句子平均長度: 46.486480672491396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([35607., 33098., 21343., 12008.,  6939.,  4608.,  2950.,  1922.,\n",
       "         1430.,   959.]),\n",
       " array([  2. ,  21.8,  41.6,  61.4,  81.2, 101. , 120.8, 140.6, 160.4,\n",
       "        180.2, 200. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len_less200 = []\n",
    "seq_txt_less200 = []\n",
    "for i in range(len(seq_len)):\n",
    "    if seq_len[i]<=200:\n",
    "        seq_len_less200.append(seq_len[i])\n",
    "        seq_txt_less200.append(seq_txt[i])\n",
    "print('句子數量:', len(seq_len_less200))\n",
    "print('句子平均長度:', np.mean(seq_len_less200))\n",
    "plt.hist(seq_len_less200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_sentence_preprocessing(sentence):\n",
    "    #先切掉空格的部分\n",
    "    del_notation = [' ', '　', '\\t']\n",
    "    for notation in del_notation:\n",
    "#        sentence = ''.join(sentence.split(notation))    \n",
    "        ' '.join(sentence.split())\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改去年的格式再切斷落"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共 50273 篇文\n"
     ]
    }
   ],
   "source": [
    "sentence_list = []\n",
    "for idx in range(len(mobile01_houseapp.content_list)): #對於每一個討論串\n",
    "    #看文章標題中有幾個指定種子\n",
    "    #文章標題跟樓主合併成同一個文\n",
    "    #sentence = mobile01_houseapp.title.iloc[idx].lower()+mobile01_houseapp.content_list.iloc[idx][0]['content'].lower()\n",
    "    #不考慮文章標題\n",
    "    for i in  range(len(mobile01_houseapp.content_list.iloc[idx])):\n",
    "        # 先在每段都加開始符號\n",
    "        sentence = mobile01_houseapp.content_list.iloc[idx][i]['content'].lower()\n",
    "        sentence = str(cut_sentence_preprocessing(sentence)) #切掉空格\n",
    "        #這邊要改成用逗號取代空格；句號取代換行。\n",
    "        \n",
    "        if sentence.find('wrote:')>0:\n",
    "            sentence = sentence[sentence.find('wrote:')+6:]\n",
    "        if sentence.find('(恕刪)')>0:\n",
    "            sentence = sentence[sentence.find('(恕刪)')+4:]\n",
    "        sentence = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', sentence, flags=re.MULTILINE)                    \n",
    "        sentence = '■開始■'+sentence\n",
    "        sentence_list.append(sentence)\n",
    "print('共', len(sentence_list), '篇文')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write\n",
    "with open('sentence_all_aSpace.txt', 'a', encoding='utf-8') as file: \n",
    "    for sentence in sentence_list:\n",
    "            file.write(sentence+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共 408992 個子句\n"
     ]
    }
   ],
   "source": [
    "#讀取DS4NER切&標記出來的句子\n",
    "#原始名稱seed\n",
    "ds4ner = pd.read_table('./Corpus_DS4NER.txt', sep='\\n', encoding='utf-8')\n",
    "sentence_ds4ner_Space = []\n",
    "for i in range(len(ds4ner)):\n",
    "    sentence_ds4ner_Space.append(ds4ner.title_name[i])\n",
    "print('共',len(sentence_ds4ner_Space), '個子句')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "往上/下最多各找2句\n",
      "句子長度限制:5~100\n",
      "找出 7195 段落!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'M=2')"
      ]
     },
     "execution_count": 1205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "up = True\n",
    "down = True\n",
    "point = 1\n",
    "s_list = []\n",
    "s_no_label = []\n",
    "s_len = []\n",
    "MAX_point = 2\n",
    "MAX_sentence_len = 100\n",
    "MIN_sentence_len = 5\n",
    "#sentence = sentence_ds4ner.copy()\n",
    "sentence = sentence_ds4ner_Space.copy()\n",
    "container = ''\n",
    "for num, s in enumerate(sentence):\n",
    "    s1=s2=''    \n",
    "    s = str(s)\n",
    "    if  len(s_no_label)>0 and s in s_no_label[len(s_no_label)-1]:\n",
    "        ;\n",
    "    elif '<BR>' in s:\n",
    "        if '■開始■' in s:\n",
    "            up=False\n",
    "            s = s.replace('■開始■', '')\n",
    "        if s[-1:] in ['。', '！', '？', '!', '?']:\n",
    "            down=False\n",
    "        candidate = ''\n",
    "        while up==True and down==True:\n",
    "            if up == True:\n",
    "                if num - point > -1 and point<=MAX_point:\n",
    "                    s1 = sentence[num-point]\n",
    "                    if '■開始■' in s1:\n",
    "                        up = False\n",
    "                        s1 = s1.replace('■開始■', '')\n",
    "                    elif s1[-1:] in ['。', '！', '？', '!', '?']:\n",
    "                        up = False\n",
    "                        s1 = ''\n",
    "                else:\n",
    "                    s1 = ''\n",
    "                    up = False\n",
    "            if down == True:\n",
    "                if num + point < len(sentence) and point<=MAX_point:\n",
    "                    s2 = sentence[num + point]\n",
    "                    if '■開始■' in s2:\n",
    "                        down = False\n",
    "                        s2 = ''\n",
    "                    elif s2[-1:] in ['。', '！', '？', '!', '?']:\n",
    "                        down = False\n",
    "                else:\n",
    "                    s2 = ''\n",
    "                    down = False\n",
    "            s = s1 + s + s2\n",
    "            s1 = s2 = ''\n",
    "            point += 1\n",
    "            no_label = delete_label(s)\n",
    "#            if MAX_sentence_len >= len(no_label) >= MIN_sentence_len:\n",
    "            if MAX_sentence_len >= len(no_label) >= MIN_sentence_len and check(s):\n",
    "                candidate=s.replace('\\n', '')\n",
    "        if len(candidate)>0:\n",
    "            no_label = delete_label(candidate)\n",
    "            s_list.append(candidate)\n",
    "            s_len.append(len(no_label))\n",
    "            s_no_label.append(no_label)\n",
    "        up = True\n",
    "        down = True\n",
    "        point = 1\n",
    "print('往上/下最多各找{}句'.format(MAX_point))\n",
    "print('句子長度限制:{}~{}'.format(MIN_sentence_len, MAX_sentence_len))\n",
    "print('找出', len(s_list), '段落!')\n",
    "\n",
    "plt.hist(s_len)\n",
    "plt.title('M='+str(MAX_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所以才淘汰特別還去找到選購同公司較高價品牌美泰克洗衣機發現現在新的惠而浦和美泰克洗衣機的機殼鋼板厚度都遠不及二十多年前舊機扎實說（還有導入部分微電腦控制面板）這些點比較讓我擔心使用壽命\n",
      "--------2524----------\n",
      "型號：faw－1011ww價錢：5990「美國frigidaire富及第」10kg超好取窄身洗衣機（福利品贈基本安裝）「5，990元」想問大家有沒有用過這台？\n",
      "--------2382----------\n",
      "（這回答有夠牛逼）已經錄這麼多影片給三星影片裡這麼明顯，又這麼誇張離譜的撞擊聲三星卻還能繼續裝死說這冰箱是很正常的那小弟也只好無私分享給大家讓大家見識一下2020年三星說沒問題的冰箱真的能讓大家對原本家裡不滿意的冰箱改觀冰箱就在我家，\n",
      "--------836----------\n",
      "日立冷氣一般使用最少用10年以上，故所以維修保養以及零件供應是非常重要的，\n",
      "--------3427----------\n",
      "想說多花點錢買個dc的風扇加上又看上奇美的簡約造型與遙控器沒想到今年七月時半夜某一晚\n",
      "--------5889----------\n",
      "有些衣物在上一台lg直立洗衣機有洗過，但是沒有變舊的感覺，\n",
      "--------2608----------\n",
      "再來跟我說最後呢dyson故障率高也不是新聞了，科技大廠，明明就是家行銷公司美國「消費者報告」將所有的dyson手持吸塵器從推薦名單中移除，原因是用戶回報5年內故障率高再查查fb上v11的官方廣告留言，壞掉頻傳，尤其是電池跟開關凹進去，\n",
      "--------64----------\n",
      "約莫傍晚遙控洗衣，下班回家就可以曬衣或烘衣了，挺方便的以下稍微解說一下app使用方式，lg也有教學可以查詢手機要安裝smartthinq，接著長按wifi鈕，連上洗衣機，連上後每次打開洗衣機液晶面板上都會出現wifi圖示，\n",
      "--------2268----------\n",
      "不論是否能抽到除濕機都希望日立能多出一些相關的影片1.各種熱源環境的評估與計算2.變頻式機器的噸數如何選擇\n",
      "--------5392----------\n",
      "變頻魔人還不快出來說...變頻很省電一定是你搞錯了你裝過大了駕駛wrote：個人1樓10－11坪，5年前裝日立4.1kw.一般設定28度，冷氣幾乎24小時開著，上個月冷氣不涼，溫度幾乎降不下來（30度吹很久都降不下來），最後清理了室內室外機冷排，\n",
      "--------4535----------\n"
     ]
    }
   ],
   "source": [
    "#把'﹍'換成' ''\n",
    "for i in range(len(s_no_label)):\n",
    "    s_no_label[i] = ' '.join(s_no_label[i].split('﹍'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(s): #句子中的廠牌還有產品名的種類\n",
    "#     findne = len(set(re.findall('(?<=<NE>)(.*?)(?=</NE>)', s)))\n",
    "#     findbr = len(set(re.findall('(?<=<BR>)(.*?)(?=</BR>)', s)))\n",
    "    findne = len(re.findall('(?<=<NE>)(.*?)(?=</NE>)', s))\n",
    "    findbr = len(re.findall('(?<=<BR>)(.*?)(?=</BR>)', s))\n",
    "#     if findbr!=len(set(re.findall('(?<=<BR>)(.*?)(?=</BR>)', s))):\n",
    "#         return False\n",
    "    if findne>0 and findbr>0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://admin:widmwidm9527@140.115.54.44:27017')\n",
    "db = client['ETL-api-creator']\n",
    "collection = db['KKBOX_Label_Ken']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 往後插入n個段落"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我的原始資料長度: 203\n",
      "原始資料長度: 1708\n",
      "插入了292筆資料\n"
     ]
    }
   ],
   "source": [
    "collection = db['KKBOX_Label_Ken']\n",
    "cursor = collection.find({}) \n",
    "data = [d for d in cursor]\n",
    "origin_collection_len = len(data)\n",
    "print('我的原始資料長度:', origin_collection_len)\n",
    "\n",
    "collection1 = db['KKBOX_Label_Ken1']\n",
    "cursor1 = collection1.find({}) \n",
    "data1 = [d for d in cursor1]\n",
    "origin_collection1_len = len(data1)\n",
    "print('原始資料長度:', origin_collection1_len)\n",
    "\n",
    "collection2 = db['KKBOX_Label_Ken2']\n",
    "\n",
    "sample_size = 2000-origin_collection1_len\n",
    "sample = np.random.randint(len(s_no_label), size=sample_size)\n",
    "count = 0\n",
    "for i in sample:\n",
    "    temp_data = {\n",
    "        'sentence_id': str(count+origin_collection1_len),\n",
    "        'sentence': s_no_label[i],\n",
    "        'aspect':[],\n",
    "        'time':0\n",
    "    }\n",
    "    collection1.insert_one(temp_data)\n",
    "    collection2.insert_one(temp_data)\n",
    "#     temp_data = {\n",
    "#         'sentence_id': str(count+origin_collection1_len+50),\n",
    "#         'sentence': s_no_label[i],\n",
    "#         'aspect':[],\n",
    "#         'time':0\n",
    "#     }\n",
    "#     collection1.insert_one(temp_data)\n",
    "#     collection2.insert_one(temp_data)\n",
    "    count+=1\n",
    "print('插入了{}筆資料'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料長度: 1708\n",
      "標記前1000筆的人有905筆資料；標記後1000筆的人有803筆資料\n",
      "正在抽出標記前1000筆的人要補充的資料\n",
      "正在抽出標記後1000筆的人要補充的資料\n",
      "標記前1000筆的人補充了95筆資料\n",
      "標記後1000筆的人補充了197筆資料\n"
     ]
    }
   ],
   "source": [
    "#針對不同標記人員，插入應該要有的資料:\n",
    "collection1 = db['KKBOX_Label_Ken1']\n",
    "cursor1 = collection1.find({}) \n",
    "data1 = [d for d in cursor1]\n",
    "origin_collection1_len = len(data1)\n",
    "print('原始資料長度:', origin_collection1_len)\n",
    "count1, count2 = 0,0\n",
    "for data in data1:\n",
    "    if int(data['sentence_id'])<1000:\n",
    "        count1+=1\n",
    "    else:\n",
    "        count2+=1\n",
    "print('標記前1000筆的人有{}筆資料；標記後1000筆的人有{}筆資料'.format(count1, count2))\n",
    "sentence_set = []\n",
    "for i in data1:\n",
    "    sentence_set.append(i['sentence'])\n",
    "    \n",
    "sample_size1 = 1000-count1\n",
    "sample_size2 = 1000-count2\n",
    "write1_data = []\n",
    "write2_data = []\n",
    "print('正在抽出標記前1000筆的人要補充的資料')\n",
    "for i in range(sample_size1):\n",
    "    flag = True\n",
    "    while flag==True:\n",
    "        sample = np.random.randint(len(s_no_label), size=1)[0]\n",
    "        if s_no_label[sample] not in sentence_set:\n",
    "            flag = False\n",
    "            sentence_set.append(s_no_label[sample])\n",
    "            temp_data = {\n",
    "                'sentence_id': str(count1+i),\n",
    "                'sentence': s_no_label[sample],\n",
    "                'aspect':[],\n",
    "                'time':0\n",
    "            }\n",
    "            write1_data.append(temp_data)\n",
    "print('正在抽出標記後1000筆的人要補充的資料')\n",
    "for i in range(sample_size2):\n",
    "    flag = True\n",
    "    while flag:\n",
    "        sample = np.random.randint(len(s_no_label), size=1)[0]\n",
    "        if s_no_label[sample] not in sentence_set:\n",
    "            flag = False\n",
    "            sentence_set.append(s_no_label[sample])\n",
    "            temp_data = {\n",
    "                'sentence_id': str(count2+i+1000),\n",
    "                'sentence': s_no_label[sample],\n",
    "                'aspect':[],\n",
    "                'time':0\n",
    "            }\n",
    "            write2_data.append(temp_data)\n",
    "count = 0\n",
    "for i in write1_data:           \n",
    "    collection1.insert_one(i)\n",
    "    collection2.insert_one(i)\n",
    "    count+=1\n",
    "print('標記前1000筆的人補充了{}筆資料'.format(count))\n",
    "count = 0\n",
    "for i in write2_data:           \n",
    "    collection1.insert_one(i)\n",
    "    collection2.insert_one(i)\n",
    "    count+=1\n",
    "print('標記後1000筆的人補充了{}筆資料'.format(count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1879,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 1879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection1 = db['KKBOX_Label_Ken1']\n",
    "cursor1 = collection1.find({}) \n",
    "data1 = [d for d in cursor1] \n",
    "collection2 = db['KKBOX_Label_Ken2']\n",
    "cursor2 = collection2.find({}) \n",
    "data2 = [d for d in cursor2] \n",
    "data1 = sorted(data1, key = lambda x: int(x['sentence_id']))\n",
    "data2 = sorted(data2, key = lambda x: int(x['sentence_id']))\n",
    "sentence_set = []\n",
    "for i in range(2000):\n",
    "    if data1[i]['sentence']!=data2[i]['sentence']:\n",
    "        print('第{}筆的句子不一樣'.format(i))\n",
    "    if data1[i]['sentence_id']!=data2[i]['sentence_id']:\n",
    "        print('第{}筆的句子id不一樣'.format(i))\n",
    "    if data1[i]['sentence_id']!=str(i):\n",
    "        print('第{}筆的句子id不對'.format(i))\n",
    "        data1[i]['sentence_id']=str(i)\n",
    "        data2[i]['sentence_id']=str(i)\n",
    "    sentence_set.append(data1[i]['sentence'])\n",
    "len(set(sentence_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modify repeat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1872,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://admin:widmwidm9527@140.115.54.44:27017')\n",
    "collection1 = db['KKBOX_Label_Ken1']\n",
    "cursor1 = collection1.find({}) \n",
    "data1 = [d for d in cursor1] \n",
    "\n",
    "collection2 = db['KKBOX_Label_Ken2']\n",
    "cursor2 = collection2.find({}) \n",
    "data2 = [d for d in cursor2] \n",
    "data1 = sorted(data1, key = lambda x: int(x['sentence_id']))\n",
    "data2 = sorted(data2, key = lambda x: int(x['sentence_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1873,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,50 兩者皆有標記\n",
      "僅0 有標記，應刪除1569\n",
      "僅0 有標記，應刪除1668\n",
      "1,52 兩者皆有標記\n",
      "2,54 兩者皆有標記\n",
      "3,56 兩者皆有標記\n",
      "4,58 兩者皆有標記\n",
      "僅4 有標記，應刪除2573\n",
      "僅4 有標記，應刪除2672\n",
      "5,60 兩者皆有標記\n",
      "6,62 兩者皆有標記\n",
      "僅6 有標記，應刪除3029\n",
      "僅6 有標記，應刪除3128\n",
      "7,64 兩者皆有標記\n",
      "8,66 兩者皆有標記\n",
      "9,68 兩者皆有標記\n",
      "僅9 有標記，應刪除799\n",
      "僅9 有標記，應刪除898\n",
      "10,70 兩者皆有標記\n",
      "11,72 兩者皆有標記\n",
      "12,74 兩者皆有標記\n",
      "僅12 有標記，應刪除3511\n",
      "僅12 有標記，應刪除3610\n",
      "13,76 兩者皆有標記\n",
      "僅13 有標記，應刪除653\n",
      "僅13 有標記，應刪除752\n",
      "14,78 兩者皆有標記\n",
      "15,80 兩者皆有標記\n",
      "僅15 有標記，應刪除2775\n",
      "僅15 有標記，應刪除2874\n",
      "16,82 兩者皆有標記\n",
      "僅16 有標記，應刪除623\n",
      "僅16 有標記，應刪除722\n",
      "17,84 兩者皆有標記\n",
      "18,86 兩者皆有標記\n",
      "19,88 兩者皆有標記\n",
      "20,90 兩者皆有標記\n",
      "僅20 有標記，應刪除469\n",
      "僅20 有標記，應刪除568\n",
      "21,92 兩者皆有標記\n",
      "22,94 兩者皆有標記\n",
      "23,96 兩者皆有標記\n",
      "24,98 兩者皆有標記\n",
      "25,100 兩者皆有標記\n",
      "26,102 兩者皆有標記\n",
      "27,104 兩者皆有標記\n",
      "28,106 兩者皆有標記\n",
      "29,108 兩者皆有標記\n",
      "30,110 兩者皆有標記\n",
      "31,112 兩者皆有標記\n",
      "32,114 兩者皆有標記\n",
      "33,116 兩者皆有標記\n",
      "34,118 兩者皆有標記\n",
      "僅34 有標記，應刪除2827\n",
      "僅34 有標記，應刪除2926\n",
      "35,120 兩者皆有標記\n",
      "36,122 兩者皆有標記\n",
      "37,124 兩者皆有標記\n",
      "僅37 有標記，應刪除3581\n",
      "僅37 有標記，應刪除3680\n",
      "38,126 兩者皆有標記\n",
      "僅38 有標記，應刪除1069\n",
      "僅38 有標記，應刪除1168\n",
      "39,128 兩者皆有標記\n",
      "僅39 有標記，應刪除3369\n",
      "僅39 有標記，應刪除3468\n",
      "40,130 兩者皆有標記\n",
      "41,132 兩者皆有標記\n",
      "僅41 有標記，應刪除2613\n",
      "僅41 有標記，應刪除2712\n",
      "42,134 兩者皆有標記\n",
      "43,136 兩者皆有標記\n",
      "44,138 兩者皆有標記\n",
      "45,140 兩者皆有標記\n",
      "僅45 有標記，應刪除3599\n",
      "僅45 有標記，應刪除3698\n",
      "46,142 兩者皆有標記\n",
      "47,144 兩者皆有標記\n",
      "48,146 兩者皆有標記\n",
      "49,148 兩者皆有標記\n",
      "僅49 有標記，應刪除989\n",
      "僅49 有標記，應刪除1088\n",
      "僅49 有標記，應刪除3459\n",
      "僅49 有標記，應刪除3558\n",
      "僅50 有標記，應刪除1569\n",
      "僅50 有標記，應刪除1668\n",
      "僅150 有標記，應刪除51\n",
      "僅152 有標記，應刪除53\n",
      "僅154 有標記，應刪除55\n",
      "僅156 有標記，應刪除57\n",
      "僅58 有標記，應刪除2573\n",
      "僅58 有標記，應刪除2672\n",
      "僅158 有標記，應刪除59\n",
      "僅160 有標記，應刪除61\n",
      "僅62 有標記，應刪除3029\n",
      "僅62 有標記，應刪除3128\n",
      "僅162 有標記，應刪除63\n",
      "僅164 有標記，應刪除65\n",
      "僅166 有標記，應刪除67\n",
      "僅68 有標記，應刪除799\n",
      "僅68 有標記，應刪除898\n",
      "僅168 有標記，應刪除69\n",
      "僅170 有標記，應刪除71\n",
      "僅172 有標記，應刪除73\n",
      "僅74 有標記，應刪除3511\n",
      "僅74 有標記，應刪除3610\n",
      "僅174 有標記，應刪除75\n",
      "僅76 有標記，應刪除653\n",
      "僅76 有標記，應刪除752\n",
      "僅176 有標記，應刪除77\n",
      "僅178 有標記，應刪除79\n",
      "僅80 有標記，應刪除2775\n",
      "僅80 有標記，應刪除2874\n",
      "僅180 有標記，應刪除81\n",
      "僅82 有標記，應刪除623\n",
      "僅82 有標記，應刪除722\n",
      "僅182 有標記，應刪除83\n",
      "僅184 有標記，應刪除85\n",
      "僅186 有標記，應刪除87\n",
      "僅188 有標記，應刪除89\n",
      "僅90 有標記，應刪除469\n",
      "僅90 有標記，應刪除568\n",
      "僅190 有標記，應刪除91\n",
      "僅192 有標記，應刪除93\n",
      "僅194 有標記，應刪除95\n",
      "僅196 有標記，應刪除97\n",
      "僅198 有標記，應刪除99\n",
      "僅200 有標記，應刪除101\n",
      "僅202 有標記，應刪除103\n",
      "僅204 有標記，應刪除105\n",
      "僅206 有標記，應刪除107\n",
      "僅208 有標記，應刪除109\n",
      "僅210 有標記，應刪除111\n",
      "僅212 有標記，應刪除113\n",
      "僅214 有標記，應刪除115\n",
      "僅216 有標記，應刪除117\n",
      "僅118 有標記，應刪除2827\n",
      "僅118 有標記，應刪除2926\n",
      "僅218 有標記，應刪除119\n",
      "僅220 有標記，應刪除121\n",
      "僅222 有標記，應刪除123\n",
      "僅400 有標記，應刪除123\n",
      "僅124 有標記，應刪除3581\n",
      "僅124 有標記，應刪除3680\n",
      "僅224 有標記，應刪除125\n",
      "僅126 有標記，應刪除1069\n",
      "僅126 有標記，應刪除1168\n",
      "僅226 有標記，應刪除127\n",
      "僅1968 有標記，應刪除127\n",
      "僅128 有標記，應刪除3369\n",
      "僅128 有標記，應刪除3468\n",
      "僅228 有標記，應刪除129\n",
      "僅230 有標記，應刪除131\n",
      "僅132 有標記，應刪除2613\n",
      "僅132 有標記，應刪除2712\n",
      "僅232 有標記，應刪除133\n",
      "僅234 有標記，應刪除135\n",
      "僅236 有標記，應刪除137\n",
      "僅238 有標記，應刪除139\n",
      "僅140 有標記，應刪除3599\n",
      "僅140 有標記，應刪除3698\n",
      "僅240 有標記，應刪除141\n",
      "僅242 有標記，應刪除143\n",
      "僅244 有標記，應刪除145\n",
      "僅246 有標記，應刪除147\n",
      "僅148 有標記，應刪除989\n",
      "僅148 有標記，應刪除1088\n",
      "僅148 有標記，應刪除3459\n",
      "僅148 有標記，應刪除3558\n",
      "僅248 有標記，應刪除149\n",
      "僅150 有標記，應刪除2719\n",
      "僅150 有標記，應刪除2818\n",
      "僅250 有標記，應刪除151\n",
      "僅252 有標記，應刪除153\n",
      "僅286 有標記，應刪除153\n",
      "僅254 有標記，應刪除155\n",
      "僅256 有標記，應刪除157\n",
      "僅258 有標記，應刪除159\n",
      "僅260 有標記，應刪除161\n",
      "僅262 有標記，應刪除163\n",
      "僅264 有標記，應刪除165\n",
      "僅266 有標記，應刪除167\n",
      "僅268 有標記，應刪除169\n",
      "僅270 有標記，應刪除171\n",
      "僅272 有標記，應刪除173\n",
      "僅174 有標記，應刪除2375\n",
      "僅174 有標記，應刪除2474\n",
      "僅274 有標記，應刪除175\n",
      "僅276 有標記，應刪除177\n",
      "僅278 有標記，應刪除179\n",
      "僅180 有標記，應刪除2519\n",
      "僅180 有標記，應刪除2618\n",
      "僅180 有標記，應刪除3137\n",
      "僅180 有標記，應刪除3236\n",
      "僅280 有標記，應刪除181\n",
      "僅282 有標記，應刪除183\n",
      "僅284 有標記，應刪除185\n",
      "僅252 有標記，應刪除187\n",
      "僅286 有標記，應刪除187\n",
      "僅288 有標記，應刪除189\n",
      "僅290 有標記，應刪除191\n",
      "僅292 有標記，應刪除193\n",
      "僅194 有標記，應刪除3777\n",
      "僅194 有標記，應刪除3876\n",
      "僅294 有標記，應刪除195\n",
      "僅296 有標記，應刪除197\n",
      "僅298 有標記，應刪除199\n",
      "僅300 有標記，應刪除201\n",
      "僅302 有標記，應刪除203\n",
      "僅204 有標記，應刪除3265\n",
      "僅204 有標記，應刪除3364\n",
      "僅304 有標記，應刪除205\n",
      "僅306 有標記，應刪除207\n",
      "僅308 有標記，應刪除209\n",
      "僅310 有標記，應刪除211\n",
      "僅312 有標記，應刪除213\n",
      "僅314 有標記，應刪除215\n",
      "僅316 有標記，應刪除217\n",
      "僅318 有標記，應刪除219\n",
      "僅320 有標記，應刪除221\n",
      "僅222 有標記，應刪除301\n",
      "222,400 兩者皆有標記\n",
      "僅322 有標記，應刪除223\n",
      "僅324 有標記，應刪除225\n",
      "僅226 有標記，應刪除1869\n",
      "226,1968 兩者皆有標記\n",
      "僅326 有標記，應刪除227\n",
      "僅228 有標記，應刪除1479\n",
      "僅228 有標記，應刪除1523\n",
      "僅228 有標記，應刪除1578\n",
      "僅228 有標記，應刪除1622\n",
      "僅328 有標記，應刪除229\n",
      "僅330 有標記，應刪除231\n",
      "僅232 有標記，應刪除3481\n",
      "僅232 有標記，應刪除3580\n",
      "僅332 有標記，應刪除233\n",
      "僅334 有標記，應刪除235\n",
      "僅336 有標記，應刪除237\n",
      "僅338 有標記，應刪除239\n",
      "僅340 有標記，應刪除241\n",
      "僅242 有標記，應刪除3313\n",
      "僅242 有標記，應刪除3412\n",
      "僅342 有標記，應刪除243\n",
      "僅244 有標記，應刪除2579\n",
      "僅244 有標記，應刪除2678\n",
      "僅344 有標記，應刪除245\n",
      "僅346 有標記，應刪除247\n",
      "僅248 有標記，應刪除1179\n",
      "僅248 有標記，應刪除1278\n",
      "僅248 有標記，應刪除2831\n",
      "僅248 有標記，應刪除2930\n",
      "僅348 有標記，應刪除249\n",
      "僅442 有標記，應刪除249\n",
      "僅350 有標記，應刪除251\n",
      "252,286 兩者皆有標記\n",
      "僅352 有標記，應刪除253\n",
      "僅354 有標記，應刪除255\n",
      "僅356 有標記，應刪除257\n",
      "僅358 有標記，應刪除259\n",
      "僅360 有標記，應刪除261\n",
      "僅362 有標記，應刪除263\n",
      "僅364 有標記，應刪除265\n",
      "僅366 有標記，應刪除267\n",
      "僅368 有標記，應刪除269\n",
      "僅370 有標記，應刪除271\n",
      "僅372 有標記，應刪除273\n",
      "僅374 有標記，應刪除275\n",
      "僅376 有標記，應刪除277\n",
      "僅378 有標記，應刪除279\n",
      "僅380 有標記，應刪除281\n",
      "僅282 有標記，應刪除2995\n",
      "僅282 有標記，應刪除3094\n",
      "僅382 有標記，應刪除283\n",
      "僅284 有標記，應刪除2265\n",
      "僅284 有標記，應刪除2364\n",
      "僅384 有標記，應刪除285\n",
      "僅386 有標記，應刪除287\n",
      "僅288 有標記，應刪除1061\n",
      "僅288 有標記，應刪除1160\n",
      "僅388 有標記，應刪除289\n",
      "僅390 有標記，應刪除291\n",
      "僅292 有標記，應刪除2955\n",
      "僅292 有標記，應刪除3054\n",
      "僅392 有標記，應刪除293\n",
      "僅394 有標記，應刪除295\n",
      "僅396 有標記，應刪除297\n",
      "僅398 有標記，應刪除299\n",
      "僅400 有標記，應刪除301\n",
      "僅302 有標記，應刪除1901\n",
      "僅302 有標記，應刪除2000\n",
      "僅402 有標記，應刪除303\n",
      "僅404 有標記，應刪除305\n",
      "僅406 有標記，應刪除307\n",
      "僅308 有標記，應刪除2427\n",
      "僅308 有標記，應刪除2526\n",
      "僅408 有標記，應刪除309\n",
      "僅410 有標記，應刪除311\n",
      "僅412 有標記，應刪除313\n",
      "僅414 有標記，應刪除315\n",
      "僅416 有標記，應刪除317\n",
      "僅318 有標記，應刪除879\n",
      "僅318 有標記，應刪除978\n",
      "僅418 有標記，應刪除319\n",
      "僅420 有標記，應刪除321\n",
      "僅422 有標記，應刪除323\n",
      "僅324 有標記，應刪除629\n",
      "僅324 有標記，應刪除728\n",
      "僅424 有標記，應刪除325\n",
      "僅426 有標記，應刪除327\n",
      "僅428 有標記，應刪除329\n",
      "僅430 有標記，應刪除331\n",
      "僅332 有標記，應刪除1921\n",
      "僅332 有標記，應刪除2020\n",
      "僅432 有標記，應刪除333\n",
      "僅334 有標記，應刪除1835\n",
      "僅334 有標記，應刪除1934\n",
      "僅334 有標記，應刪除2139\n",
      "僅334 有標記，應刪除2238\n",
      "僅434 有標記，應刪除335\n",
      "僅336 有標記，應刪除1431\n",
      "僅336 有標記，應刪除1530\n",
      "僅436 有標記，應刪除337\n",
      "僅338 有標記，應刪除3721\n",
      "僅338 有標記，應刪除3820\n",
      "僅438 有標記，應刪除339\n",
      "僅440 有標記，應刪除341\n",
      "僅348 有標記，應刪除343\n",
      "僅442 有標記，應刪除343\n",
      "僅444 有標記，應刪除345\n",
      "僅446 有標記，應刪除347\n",
      "348,442 兩者皆有標記\n",
      "僅448 有標記，應刪除349\n",
      "僅450 有標記，應刪除351\n",
      "僅352 有標記，應刪除2043\n",
      "僅352 有標記，應刪除2142\n",
      "僅452 有標記，應刪除353\n",
      "僅454 有標記，應刪除355\n",
      "僅356 有標記，應刪除3949\n",
      "僅356 有標記，應刪除3999\n",
      "僅456 有標記，應刪除357\n",
      "僅360 有標記，應刪除1497\n",
      "僅360 有標記，應刪除1596\n",
      "僅460 有標記，應刪除361\n",
      "僅462 有標記，應刪除363\n",
      "僅464 有標記，應刪除365\n",
      "僅466 有標記，應刪除367\n",
      "僅368 有標記，應刪除803\n",
      "僅368 有標記，應刪除902\n",
      "僅368 有標記，應刪除2277\n",
      "僅368 有標記，應刪除2376\n",
      "僅468 有標記，應刪除369\n",
      "僅374 有標記，應刪除813\n",
      "僅374 有標記，應刪除912\n",
      "僅390 有標記，應刪除3823\n",
      "僅390 有標記，應刪除3922\n",
      "僅406 有標記，應刪除2657\n",
      "僅406 有標記，應刪除2756\n",
      "僅408 有標記，應刪除1829\n",
      "僅408 有標記，應刪除1928\n",
      "僅412 有標記，應刪除729\n",
      "僅412 有標記，應刪除828\n",
      "僅414 有標記，應刪除1345\n",
      "僅414 有標記，應刪除1444\n",
      "僅418 有標記，應刪除3771\n",
      "僅418 有標記，應刪除3870\n",
      "僅422 有標記，應刪除3013\n",
      "僅422 有標記，應刪除3112\n",
      "僅430 有標記，應刪除3333\n",
      "僅430 有標記，應刪除3432\n",
      "僅432 有標記，應刪除2575\n",
      "僅432 有標記，應刪除2674\n",
      "僅436 有標記，應刪除1799\n",
      "僅436 有標記，應刪除1898\n",
      "僅438 有標記，應刪除1969\n",
      "僅438 有標記，應刪除2068\n",
      "僅440 有標記，應刪除2369\n",
      "僅440 有標記，應刪除2468\n",
      "僅1976 有標記，應刪除807\n",
      "僅1976 有標記，應刪除906\n",
      "僅1976 有標記，應刪除1809\n",
      "僅1950 有標記，應刪除1851\n",
      "僅1952 有標記，應刪除1853\n",
      "僅1954 有標記，應刪除1855\n",
      "僅1956 有標記，應刪除1857\n",
      "僅1958 有標記，應刪除1859\n",
      "僅1960 有標記，應刪除1861\n",
      "僅1962 有標記，應刪除1863\n",
      "僅1964 有標記，應刪除1865\n",
      "僅1966 有標記，應刪除1867\n",
      "僅1968 有標記，應刪除1869\n",
      "僅1970 有標記，應刪除1871\n",
      "僅1972 有標記，應刪除1873\n",
      "僅1974 有標記，應刪除1875\n",
      "僅1976 有標記，應刪除1877\n",
      "僅1978 有標記，應刪除1879\n",
      "僅1980 有標記，應刪除1881\n",
      "僅1982 有標記，應刪除1883\n",
      "僅1984 有標記，應刪除1885\n",
      "僅1986 有標記，應刪除1887\n",
      "僅1988 有標記，應刪除1889\n",
      "僅1990 有標記，應刪除1891\n",
      "僅1976 有標記，應刪除1908\n",
      "僅1962 有標記，應刪除2943\n",
      "僅1962 有標記，應刪除3042\n",
      "僅1972 有標記，應刪除2327\n",
      "僅1972 有標記，應刪除2426\n",
      "僅1982 有標記，應刪除1983\n",
      "僅1982 有標記，應刪除2082\n",
      "共有54筆資料被重複標記到\n"
     ]
    }
   ],
   "source": [
    "#重複配對\n",
    "data = data1\n",
    "rep = {}\n",
    "delid = []\n",
    "count=0\n",
    "for i in range(len(data)):\n",
    "    j = i+1\n",
    "    while j<len(data):\n",
    "        if data[i]['sentence']==data[j]['sentence']:\n",
    "            rep[i]=j\n",
    "            if len(data[i]['aspect'])>0 and len(data[j]['aspect'])>0:\n",
    "                print('{},{} 兩者皆有標記'.format(i,j))\n",
    "                count+=1\n",
    "                delid.append(j)\n",
    "            elif len(data[i]['aspect'])>0 and len(data[j]['aspect'])==0:\n",
    "                print('僅{} 有標記，應刪除{}'.format(i,j))\n",
    "                delid.append(j)\n",
    "            elif len(data[j]['aspect'])>0 and len(data[i]['aspect'])==0:\n",
    "                print('僅{} 有標記，應刪除{}'.format(j,i))\n",
    "                delid.append(i)\n",
    "            else:\n",
    "                delid.append(j) \n",
    "        j+=1\n",
    "print('共有{}筆資料被重複標記到'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1874,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要保存的index有1708個\n"
     ]
    }
   ],
   "source": [
    "delid = list(set(delid))\n",
    "storeid = []\n",
    "for i in range(len(data1)):\n",
    "    if i not in delid:\n",
    "        storeid.append(i)\n",
    "actual_storeid = []\n",
    "for i in storeid:\n",
    "    actual_storeid.append(int(data1[i]['sentence_id']))\n",
    "print('要保存的index有{}個'.format(len(storeid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1875,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(905, 1803)"
      ]
     },
     "execution_count": 1875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count1=0\n",
    "count2=1000\n",
    "for i in delid:\n",
    "    data1[i]['sentence_id']='-1'\n",
    "    data2[i]['sentence_id']='-1'\n",
    "for i in storeid:\n",
    "    if int(data1[i]['sentence_id'])<1000:\n",
    "        data1[i]['sentence_id']=str(count1)\n",
    "        data2[i]['sentence_id']=str(count1)        \n",
    "        count1+=1\n",
    "    else:\n",
    "        data1[i]['sentence_id']=str(count2)\n",
    "        data2[i]['sentence_id']=str(count2)\n",
    "        count2+=1\n",
    "(count1, count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1877,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共重新寫入了1708筆資料\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for idx in range(len(data1)):\n",
    "    if data1[idx]['sentence_id']!='-1':        \n",
    "        collection1.insert_one(data1[idx])\n",
    "        collection2.insert_one(data2[idx])\n",
    "        count += 1\n",
    "print('共重新寫入了{}筆資料'.format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Whole data for a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1876,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1刪除了4000筆資料\n",
      "data2刪除了4000筆資料\n"
     ]
    }
   ],
   "source": [
    "collection1 = db['KKBOX_Label_Ken1']\n",
    "collection2 = db['KKBOX_Label_Ken2']\n",
    "\n",
    "cursor1 = collection1.find({}) \n",
    "dta1 = [d for d in cursor1] \n",
    "cursor2 = collection2.find({}) \n",
    "dta2 = [d for d in cursor2] \n",
    "\n",
    "for i in range(len(dta1)):\n",
    "    collection1.delete_many({\"sentence_id\":str(i)})    \n",
    "print('data1刪除了{}筆資料'.format(len(dta1)))\n",
    "\n",
    "for i in range(len(dta2)):\n",
    "    collection2.delete_many({\"sentence_id\":str(i)})\n",
    "print('data2刪除了{}筆資料'.format(len(dta2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db['KKBOX_Label_Ken']\n",
    "cursor = collection.find({}) \n",
    "# data = [d for d in cursor] \n",
    "# for i in range(len(data)):\n",
    "#     collection.delete_many({\"sentence_id\":str(i)})\n",
    "data = data_copy.copy()\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i])):\n",
    "        data[i]['time']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標記結果統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均每段落出現產品名稱數:0.37935166876385645\n",
      "平均每段落出現產品廠牌數:1.4931391934807359\n",
      "最大出現產品名稱數:7\n",
      "最大出現產品廠牌數:9\n"
     ]
    }
   ],
   "source": [
    "countne = []\n",
    "countbr = []\n",
    "for s in s_list:\n",
    "    countne.append(len(re.findall('(?<=<NE>)(.*?)(?=</NE>)', s)))\n",
    "    countbr.append(len(re.findall('(?<=<BR>)(.*?)(?=</BR>)', s)))\n",
    "print('平均每段落出現產品名稱數:{}'.format(np.mean(countne)))\n",
    "print('平均每段落出現產品廠牌數:{}'.format(np.mean(countbr)))\n",
    "print('最大出現產品名稱數:{}'.format(max(countne)))\n",
    "print('最大出現產品廠牌數:{}'.format(max(countbr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = collection.find({}) \n",
    "data = [d for d in cursor] \n",
    "data = data[-30:]\n",
    "cursor1 = collection1.find({}) \n",
    "data1 = [d for d in cursor1]\n",
    "data1 = data1[-30:]\n",
    "cursor2 = collection2.find({}) \n",
    "data2 = [d for d in cursor2][-30:]\n",
    "data2 = data2[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT標記數量一樣的段落數: 12\n",
      "ASPECT標記完全一樣的段落數: 4\n",
      "ASPECT標記完全一樣的段落數(2人): 6\n",
      "mean #aspect =  2.7888888888888888\n",
      "平均每個段落僅提及實體比例= 0.5458597883597884\n",
      "僅提及實體的段落比例= 0.3888888888888889\n"
     ]
    }
   ],
   "source": [
    "count1 = 0\n",
    "count2 = 0\n",
    "countlen = 0\n",
    "length = []\n",
    "noasp = []\n",
    "sennoasp = []\n",
    "for i in range(len(data)):\n",
    "    length.append(len(data[i]['aspect']))\n",
    "    length.append(len(data1[i]['aspect']))\n",
    "    length.append(len(data2[i]['aspect']))\n",
    "    \n",
    "    if len(data1[i]['aspect'])==len(data2[i]['aspect'])==len(data[i]['aspect']):\n",
    "        countlen+=1\n",
    "        if same3(data[i]['aspect'], data1[i]['aspect'], data2[i]['aspect']):\n",
    "            count1+=1\n",
    "    if len(data1[i]['aspect'])==len(data2[i]['aspect']):\n",
    "        if same2(data1[i]['aspect'], data2[i]['aspect']):\n",
    "            count2+=1\n",
    "    notasp = 0\n",
    "    if len(data[i]['aspect'])>0:\n",
    "        for j in data[i]['aspect']:\n",
    "            if noaspect(j):\n",
    "                notasp+=1\n",
    "        noasp.append(notasp/len(data[i]['aspect']))\n",
    "    notasp = 0\n",
    "    if len(data1[i]['aspect'])>0:\n",
    "        for j in data1[i]['aspect']:\n",
    "            if noaspect(j):\n",
    "                notasp+=1\n",
    "        noasp.append(notasp/len(data1[i]['aspect']))\n",
    "    notasp = 0\n",
    "    if len(data2[i]['aspect'])>0:\n",
    "        for j in data2[i]['aspect']:\n",
    "            if noaspect(j):\n",
    "                notasp+=1\n",
    "    noasp.append(notasp/len(data2[i]['aspect']))\n",
    "    \n",
    "    sennoasp.append(sennoaspect(data[i]['aspect']))\n",
    "    sennoasp.append(sennoaspect(data1[i]['aspect']))\n",
    "    sennoasp.append(sennoaspect(data2[i]['aspect']))\n",
    "\n",
    "print(\"ASPECT標記數量一樣的段落數:\",countlen)\n",
    "print(\"ASPECT標記完全一樣的段落數:\",count1)\n",
    "print(\"ASPECT標記完全一樣的段落數(2人):\",count2)\n",
    "print(\"mean #aspect = \", np.mean(length))\n",
    "print(\"平均每個段落僅提及實體比例=\", np.mean(noasp))\n",
    "print(\"僅提及實體的段落比例=\", np.mean(sennoasp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same3(data, data1, data2):\n",
    "    dataset = set()\n",
    "    data1set = set()\n",
    "    data2set = set()\n",
    "    for i in range(len(data)):\n",
    "        datastr = str(data[i]['product_name'])+str(data[i]['product_brand'])+str(data[i]['aspect_category'])+str(data[i]['aspect_term'])+str(data[i]['opinion_word'])+str(data[i]['sentiment'])\n",
    "        data1str = str(data1[i]['product_name'])+str(data1[i]['product_brand'])+str(data1[i]['aspect_category'])+str(data1[i]['aspect_term'])+str(data1[i]['opinion_word'])+str(data1[i]['sentiment'])\n",
    "        data2str = str(data2[i]['product_name'])+str(data2[i]['product_brand'])+str(data2[i]['aspect_category'])+str(data2[i]['aspect_term'])+str(data2[i]['opinion_word'])+str(data2[i]['sentiment'])\n",
    "#         datastr = str(data[i]['product_name'])+str(data[i]['product_brand'])+str(data[i]['aspect_category'])+str(data[i]['sentiment'])\n",
    "#         data1str = str(data1[i]['product_name'])+str(data1[i]['product_brand'])+str(data1[i]['aspect_category'])+str(data1[i]['sentiment'])\n",
    "#         data2str = str(data2[i]['product_name'])+str(data2[i]['product_brand'])+str(data2[i]['aspect_category'])+str(data2[i]['sentiment'])\n",
    "        dataset.add(datastr)\n",
    "        data1set.add(data1str)\n",
    "        data2set.add(data2str)\n",
    "    if dataset==data1set==data2set:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def same2(data, data1):\n",
    "    dataset = set()\n",
    "    data1set = set()\n",
    "    for i in range(len(data)):\n",
    "        datastr = str(data[i]['product_name'])+str(data[i]['product_brand'])+str(data[i]['aspect_category'])+str(data[i]['aspect_term'])+str(data[i]['opinion_word'])+str(data[i]['sentiment'])\n",
    "        data1str = str(data1[i]['product_name'])+str(data1[i]['product_brand'])+str(data1[i]['aspect_category'])+str(data1[i]['aspect_term'])+str(data1[i]['opinion_word'])+str(data1[i]['sentiment'])\n",
    "        dataset.add(datastr)\n",
    "        data1set.add(data1str)\n",
    "    if dataset==data1set:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人員一(姵芸) 平均標一筆: 2.91 分鐘\n",
      "人員二(怡萱) 平均標一筆: 1.99 分鐘\n",
      "人員三(意慈) 平均標一筆: 5.11 分鐘\n",
      "人員四(慕耘) 平均標一筆: 2.76 分鐘\n"
     ]
    }
   ],
   "source": [
    "#取時間(按序排)在25%~75%間的，為了排除極值情況所以這樣計算。\n",
    "time1.sort()\n",
    "print('人員一(姵芸) 平均標一筆:',round(np.mean(time1[int(len(time1)/4):int(3*len(time1)/4)])/60,2),'分鐘')\n",
    "time2.sort()\n",
    "print('人員二(怡萱) 平均標一筆:',round(np.mean(time2[int(len(time2)/4):int(3*len(time2)/4)])/60,2),'分鐘')\n",
    "time3.sort()\n",
    "print('人員三(意慈) 平均標一筆:',round(np.mean(time3[int(len(time3)/4):int(3*len(time3)/4)])/60,2),'分鐘')\n",
    "time4.sort()\n",
    "print('人員四(慕耘) 平均標一筆:',round(np.mean(time4[int(len(time4)/4):int(3*len(time4)/4)])/60,2),'分鐘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "紀錄時間 2020/12/22-13:26:07\n",
      "data 共寫了203個文\n",
      "data1 共寫了100個文\n",
      "data2 共寫了100個文\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "time_result = time.strftime(\"%Y-%m-%d %Hh%Mm%Ss\", time.localtime())\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://admin:widmwidm9527@140.115.54.44:27017')\n",
    "db = client['ETL-api-creator']\n",
    "collection = db['KKBOX_Label_Ken']\n",
    "cursor = collection.find({}) \n",
    "data = [d for d in cursor] \n",
    "\n",
    "collection1 = db['KKBOX_Label_Ken1']\n",
    "cursor1 = collection1.find({}) \n",
    "data1 = [d for d in cursor1] \n",
    "\n",
    "collection2 = db['KKBOX_Label_Ken2']\n",
    "cursor2 = collection2.find({}) \n",
    "data2 = [d for d in cursor2] \n",
    "#make directory\n",
    "os.mkdir(time_result)\n",
    "os.chdir(time_result)\n",
    "#write json\n",
    "print('紀錄時間', time.strftime(\"%Y/%m/%d-%H:%M:%S\", time.localtime()))\n",
    "with open('label.json', 'w', encoding='utf8') as file:\n",
    "    count = 0\n",
    "    for d in data:\n",
    "        d.pop('_id')\n",
    "        ret = json.dumps(d, ensure_ascii=False)\n",
    "        file.write(ret)\n",
    "        file.write('\\n')\n",
    "        count+=1\n",
    "    print('data 共寫了{}個文'.format(count))\n",
    "    \n",
    "with open('label1.json', 'w', encoding='utf8') as file:\n",
    "    count = 0\n",
    "    for d in data1:\n",
    "        d.pop('_id')\n",
    "        ret = json.dumps(d, ensure_ascii=False)\n",
    "        file.write(ret)\n",
    "        file.write('\\n')\n",
    "        count+=1\n",
    "    print('data1 共寫了{}個文'.format(count))\n",
    "    \n",
    "with open('label2.json', 'w', encoding='utf8') as file:\n",
    "    count = 0\n",
    "    for d in data2:\n",
    "        d.pop('_id')\n",
    "        ret = json.dumps(d, ensure_ascii=False)\n",
    "        file.write(ret)\n",
    "        file.write('\\n')\n",
    "        count+=1\n",
    "    print('data2 共寫了{}個文'.format(count))\n",
    "os.chdir('..')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
